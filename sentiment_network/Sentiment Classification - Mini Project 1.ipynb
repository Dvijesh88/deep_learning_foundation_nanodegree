{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification & How To \"Frame Problems\" for a Neural Network\n",
    "\n",
    "by Andrew Trask\n",
    "\n",
    "- **Twitter**: @iamtrask\n",
    "- **Blog**: http://iamtrask.github.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What You Should Already Know\n",
    "\n",
    "- neural networks, forward and back-propagation\n",
    "- stochastic gradient descent\n",
    "- mean squared error\n",
    "- and train/test splits\n",
    "\n",
    "### Where to Get Help if You Need it\n",
    "- Re-watch previous Udacity Lectures\n",
    "- Leverage the recommended Course Reading Material - [Grokking Deep Learning](https://www.manning.com/books/grokking-deep-learning) (40% Off: **traskud17**)\n",
    "- Shoot me a tweet @iamtrask\n",
    "\n",
    "\n",
    "### Tutorial Outline:\n",
    "\n",
    "- Intro: The Importance of \"Framing a Problem\"\n",
    "\n",
    "\n",
    "- Curate a Dataset\n",
    "- Developing a \"Predictive Theory\"\n",
    "- **PROJECT 1**: Quick Theory Validation\n",
    "\n",
    "\n",
    "- Transforming Text to Numbers\n",
    "- **PROJECT 2**: Creating the Input/Output Data\n",
    "\n",
    "\n",
    "- Putting it all together in a Neural Network\n",
    "- **PROJECT 3**: Building our Neural Network\n",
    "\n",
    "\n",
    "- Understanding Neural Noise\n",
    "- **PROJECT 4**: Making Learning Faster by Reducing Noise\n",
    "\n",
    "\n",
    "- Analyzing Inefficiencies in our Network\n",
    "- **PROJECT 5**: Making our Network Train and Run Faster\n",
    "\n",
    "\n",
    "- Further Noise Reduction\n",
    "- **PROJECT 6**: Reducing Noise by Strategically Reducing the Vocabulary\n",
    "\n",
    "\n",
    "- Analysis: What's going on in the weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "56bb3cba-260c-4ebe-9ed6-b995b4c72aa3"
    }
   },
   "source": [
    "# Lesson: Curate a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "eba2b193-0419-431e-8db9-60f34dd3fe83"
    }
   },
   "outputs": [],
   "source": [
    "def pretty_print_review_and_label(i):\n",
    "    print(labels[i] + \"\\t:\\t\" + reviews[i][:80] + \"...\")\n",
    "\n",
    "g = open('reviews.txt','r') # What we know!\n",
    "reviews = list(map(lambda x:x[:-1],g.readlines()))\n",
    "g.close()\n",
    "\n",
    "g = open('labels.txt','r') # What we WANT to know!\n",
    "labels = list(map(lambda x:x[:-1].upper(),g.readlines()))\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "bb95574b-21a0-4213-ae50-34363cf4f87f"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e0408810-c424-4ed4-afb9-1735e9ddbd0a"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: Develop a Predictive Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e67a709f-234f-4493-bae6-4fb192141ee0"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.txt \t : \t reviews.txt\n",
      "\n",
      "NEGATIVE\t:\tthis movie is terrible but it has some good effects .  ...\n",
      "POSITIVE\t:\tadrian pasdar is excellent is this film . he makes a fascinating woman .  ...\n",
      "NEGATIVE\t:\tcomment this movie is impossible . is terrible  very improbable  bad interpretat...\n",
      "POSITIVE\t:\texcellent episode movie ala pulp fiction .  days   suicides . it doesnt get more...\n",
      "NEGATIVE\t:\tif you haven  t seen this  it  s terrible . it is pure trash . i saw this about ...\n",
      "POSITIVE\t:\tthis schiffer guy is a real genius  the movie is of excellent quality and both e...\n"
     ]
    }
   ],
   "source": [
    "print(\"labels.txt \\t : \\t reviews.txt\\n\")\n",
    "pretty_print_review_and_label(2137)\n",
    "pretty_print_review_and_label(12816)\n",
    "pretty_print_review_and_label(6267)\n",
    "pretty_print_review_and_label(21934)\n",
    "pretty_print_review_and_label(5297)\n",
    "pretty_print_review_and_label(4998)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Lets first try to check the lenghts of each positive/negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive review length mean: 683.81168\n",
      "Negative review length mean: 662.319\n"
     ]
    }
   ],
   "source": [
    "positive_review_length = 0\n",
    "negative_review_length = 0\n",
    "for i in range(len(reviews)):\n",
    "    if labels[i] == 'POSITIVE':\n",
    "        positive_review_length += len(reviews[i])\n",
    "    else:\n",
    "        negative_review_length += len(reviews[i])\n",
    "    \n",
    "print(\"Positive review length mean: {}\\nNegative review length mean: {}\".format(\n",
    "        positive_review_length / len(reviews),\n",
    "        negative_review_length / len(reviews)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Both negative reviews and positive reviews seems to have the same lenght. There doesn't seems to be any correlation between size of a review and its sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Lets try to find which words appear the most in positive/negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive common words:\n",
      "the, ., and, a, of, to, is, in, br, it, i, that, this, s, as, with, for, was, film, but, movie, his, on, you, he, are, not, t, one, have, be, by, all, who, an, at, from, her, they, has, so, like, about, very, out, there, she, what, or, good, more, when, some, if, just, can, story, time, my, great, well, up, which, their, see, also, we, really, would, will, me, had, only, him, even, most, other, were, first, than, much, its, no, into, people, best, love, get, how, life, been, because, way, do, made, films, them, after, many, two, \n",
      "\n",
      "Most negative common words:\n",
      "., the, a, and, of, to, br, is, it, i, in, this, that, s, was, movie, for, but, with, as, t, film, you, on, not, have, are, be, he, one, they, at, his, all, so, like, there, just, by, or, an, who, from, if, about, out, what, some, no, her, even, can, has, good, bad, would, up, only, more, when, she, really, time, had, my, were, which, very, me, see, don, we, their, do, story, than, been, much, get, because, people, then, make, how, could, any, into, made, first, other, well, too, them, plot, movies, acting, will, way, most, him, "
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "positive_words_dict = {}\n",
    "negative_words_dict = {}\n",
    "\n",
    "def get_range(dictionary, begin, end):\n",
    "    return {k: v for k, v in dictionary.items() if begin <= k <= end}\n",
    "\n",
    "def add_words_to_dictionnary(sentence, words_dict):\n",
    "    wordcount = Counter(sentence.split())\n",
    "    for key, value in wordcount.items():\n",
    "        if key in words_dict:\n",
    "            words_dict[key] += wordcount[key]\n",
    "        else:\n",
    "            words_dict[key] = wordcount[key]\n",
    "    \n",
    "for i in range(len(reviews)):\n",
    "    if labels[i] == 'POSITIVE':\n",
    "        add_words_to_dictionnary(reviews[i], positive_words_dict)\n",
    "    else:\n",
    "        add_words_to_dictionnary(reviews[i], negative_words_dict)\n",
    "   \n",
    "sorted_positives = sorted(positive_words_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_negatives = sorted(negative_words_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "print_n = 100\n",
    "\n",
    "print(\"Most positive common words:\")\n",
    "for i in range(0, print_n):\n",
    "    print(sorted_positives[i][0], end=', ')\n",
    "  \n",
    "print(\"\\n\\nMost negative common words:\")\n",
    "for i in range(0, print_n):\n",
    "    print(sorted_negatives[i][0], end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it is still not very useful as the most common words (we would have guess the result wihout even running the code) is a bunch of what we call **stopwords** ('the', 'it', 'i'...) which are the most common words used in english but also the ones for which we care the less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets remove the stopwords and only keep the relevant ones\n",
    "\n",
    "\n",
    "<font color=\"red\">Careful: The operations in this section may take some time to execute</font>\n",
    "\n",
    "For this task lets use the nltk library which contains a bunch of stopwords and will help us remove them from our lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive common words: ['.', 'br', 'film', 'movie', 'one', 'like', 'good', 'story', 'time', 'great', 'well', 'see', 'also', 'really', 'would', 'even', 'first', 'much', 'people', 'best', 'love', 'get', 'life', 'way', 'made', 'films', 'many', 'two', 'think', 'movies', 'characters', 'character', 'man', 'show', 'watch', 'seen', 'little', 'still', 'make', 'could', 'never', 'know', 'years', 'ever', 'end', 'real', 'scene', 'back', 'though', 'new']\n",
      "\n",
      "Most negative common words: ['.', 'br', 'movie', 'film', 'one', 'like', 'even', 'good', 'bad', 'would', 'really', 'time', 'see', 'story', 'much', 'get', 'people', 'make', 'could', 'made', 'first', 'well', 'plot', 'movies', 'acting', 'way', 'think', 'also', 'characters', 'watch', 'character', 'better', 'know', 'seen', 'ever', 'never', 'two', 'little', 'films', 'nothing', 'say', 'end', 'something', 'many', 'thing', 'show', 'scene', 'scenes', 'go', 'great']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "filtered_positive_words = []\n",
    "filtered_negative_words = []\n",
    "\n",
    "for i in range(len(sorted_positives)):\n",
    "    if sorted_positives[i][0] not in stopwords.words('english'):\n",
    "        filtered_positive_words.append(sorted_positives[i][0])\n",
    "        \n",
    "for i in range(len(sorted_negatives)):\n",
    "    if sorted_negatives[i][0] not in stopwords.words('english'):\n",
    "        filtered_negative_words.append(sorted_negatives[i][0])\n",
    "        \n",
    "print(\"Most positive words:\", filtered_positive_words[:50])\n",
    "print(\"\\nMost negative words:\", filtered_negative_words[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some words such as \"great\" are at the top of the list of positive words and other words such as \"bad\" are at the top of the list for negative words. But unfortunately we can also see that in the negative list a lot of \"positive\" words can be found at the top of the list such as \"like\", \"good\"..."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
